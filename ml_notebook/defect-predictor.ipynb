{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "import pickle\n",
    "# Import classification report and confusion matrix to evaluate predictions\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.075758</td>\n",
       "      <td>1094.484426</td>\n",
       "      <td>31822.963837</td>\n",
       "      <td>0.364828</td>\n",
       "      <td>1767.942435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29.390625</td>\n",
       "      <td>1066.415964</td>\n",
       "      <td>31342.631700</td>\n",
       "      <td>0.355472</td>\n",
       "      <td>1741.257317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>17.042553</td>\n",
       "      <td>1023.802528</td>\n",
       "      <td>17448.209045</td>\n",
       "      <td>0.341268</td>\n",
       "      <td>969.344947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.058824</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>17.386364</td>\n",
       "      <td>964.579802</td>\n",
       "      <td>16770.535199</td>\n",
       "      <td>0.321527</td>\n",
       "      <td>931.696400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>23.166667</td>\n",
       "      <td>1594.915264</td>\n",
       "      <td>36948.870292</td>\n",
       "      <td>0.531638</td>\n",
       "      <td>2052.715016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1      2     3      4      5     6          7            8   \\\n",
       "0  13.0  33.0  101.0  19.0   91.0  192.0  52.0  29.075758  1094.484426   \n",
       "1  13.0  32.0   99.0  19.0   89.0  188.0  51.0  29.390625  1066.415964   \n",
       "2   8.0  47.0   89.0  18.0   81.0  170.0  65.0  17.042553  1023.802528   \n",
       "3   6.0  44.0   85.0  18.0   77.0  162.0  62.0  17.386364   964.579802   \n",
       "4  12.0  51.0  139.0  17.0  123.0  262.0  68.0  23.166667  1594.915264   \n",
       "\n",
       "             9         10           11   12    13    14         15   16  \n",
       "0  31822.963837  0.364828  1767.942435  1.0  36.0  27.0  36.111111  1.0  \n",
       "1  31342.631700  0.355472  1741.257317  1.0  36.0  26.0  36.111111  0.0  \n",
       "2  17448.209045  0.341268   969.344947  1.0  17.0  19.0  47.058824  1.0  \n",
       "3  16770.535199  0.321527   931.696400  1.0  16.0  19.0  37.500000  0.0  \n",
       "4  36948.870292  0.531638  2052.715016  1.0  34.0  39.0  35.294118  1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('metrics/atom_atom_metrics.pkl', 'rb') as f:\n",
    "  metrics = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "#dataset = dataset.dropna(axis=0, how='any')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4504, 17)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4504, 17)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(df.columns[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]], axis=1)\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4319918 ,  0.4071154 ,  0.60657414, ...,  0.81259798,\n",
       "        -0.09055103, -0.15253181],\n",
       "       [ 1.4319918 ,  0.36336859,  0.5784916 , ...,  0.81259798,\n",
       "        -0.09686515, -0.15253181],\n",
       "       [ 0.5877914 ,  1.01957082,  0.4380789 , ..., -0.04911959,\n",
       "        -0.14106401,  0.17864626],\n",
       "       ...,\n",
       "       [-0.08756892, -0.20534002,  0.14321223, ...,  0.2683553 ,\n",
       "        -0.04635217, -0.7407436 ],\n",
       "       [-0.08756892, -0.42407409, -0.13761318, ..., -0.18518026,\n",
       "        -0.15369225, -0.38061393],\n",
       "       [ 0.25011124, -0.24908683,  0.22745985, ...,  0.22300175,\n",
       "        -0.11580752, -0.45577143]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop(df.columns[16], axis=1))\n",
    "# Use scaler object to conduct a transforms\n",
    "scaled_features = scaler.transform(df.drop(df.columns[16], axis=1))\n",
    "# Review the array of values generated from the scaled features process\n",
    "scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.431992</td>\n",
       "      <td>0.407115</td>\n",
       "      <td>0.606574</td>\n",
       "      <td>1.900839</td>\n",
       "      <td>0.687316</td>\n",
       "      <td>0.644991</td>\n",
       "      <td>0.736075</td>\n",
       "      <td>1.939663</td>\n",
       "      <td>0.541394</td>\n",
       "      <td>0.796666</td>\n",
       "      <td>0.541394</td>\n",
       "      <td>0.796666</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>-0.090551</td>\n",
       "      <td>-0.152532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.431992</td>\n",
       "      <td>0.363369</td>\n",
       "      <td>0.578492</td>\n",
       "      <td>1.900839</td>\n",
       "      <td>0.653788</td>\n",
       "      <td>0.614349</td>\n",
       "      <td>0.698301</td>\n",
       "      <td>1.972392</td>\n",
       "      <td>0.509773</td>\n",
       "      <td>0.777374</td>\n",
       "      <td>0.509773</td>\n",
       "      <td>0.777374</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>-0.096865</td>\n",
       "      <td>-0.152532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587791</td>\n",
       "      <td>1.019571</td>\n",
       "      <td>0.438079</td>\n",
       "      <td>1.714113</td>\n",
       "      <td>0.519678</td>\n",
       "      <td>0.476464</td>\n",
       "      <td>1.227145</td>\n",
       "      <td>0.688886</td>\n",
       "      <td>0.461767</td>\n",
       "      <td>0.219341</td>\n",
       "      <td>0.461767</td>\n",
       "      <td>0.219341</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>-0.049120</td>\n",
       "      <td>-0.141064</td>\n",
       "      <td>0.178646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250111</td>\n",
       "      <td>0.888330</td>\n",
       "      <td>0.381914</td>\n",
       "      <td>1.714113</td>\n",
       "      <td>0.452623</td>\n",
       "      <td>0.415182</td>\n",
       "      <td>1.113821</td>\n",
       "      <td>0.724623</td>\n",
       "      <td>0.395050</td>\n",
       "      <td>0.192124</td>\n",
       "      <td>0.395050</td>\n",
       "      <td>0.192124</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>-0.094473</td>\n",
       "      <td>-0.141064</td>\n",
       "      <td>-0.110517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.263152</td>\n",
       "      <td>1.194558</td>\n",
       "      <td>1.140142</td>\n",
       "      <td>1.527387</td>\n",
       "      <td>1.223758</td>\n",
       "      <td>1.181210</td>\n",
       "      <td>1.340468</td>\n",
       "      <td>1.325450</td>\n",
       "      <td>1.105151</td>\n",
       "      <td>1.002534</td>\n",
       "      <td>1.105151</td>\n",
       "      <td>1.002534</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>0.721891</td>\n",
       "      <td>-0.014782</td>\n",
       "      <td>-0.177247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.431992  0.407115  0.606574  1.900839  0.687316  0.644991  0.736075   \n",
       "1  1.431992  0.363369  0.578492  1.900839  0.653788  0.614349  0.698301   \n",
       "2  0.587791  1.019571  0.438079  1.714113  0.519678  0.476464  1.227145   \n",
       "3  0.250111  0.888330  0.381914  1.714113  0.452623  0.415182  1.113821   \n",
       "4  1.263152  1.194558  1.140142  1.527387  1.223758  1.181210  1.340468   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  1.939663  0.541394  0.796666  0.541394  0.796666  0.102213  0.812598   \n",
       "1  1.972392  0.509773  0.777374  0.509773  0.777374  0.102213  0.812598   \n",
       "2  0.688886  0.461767  0.219341  0.461767  0.219341  0.102213 -0.049120   \n",
       "3  0.724623  0.395050  0.192124  0.395050  0.192124  0.102213 -0.094473   \n",
       "4  1.325450  1.105151  1.002534  1.105151  1.002534  0.102213  0.721891   \n",
       "\n",
       "         14        15  \n",
       "0 -0.090551 -0.152532  \n",
       "1 -0.096865 -0.152532  \n",
       "2 -0.141064  0.178646  \n",
       "3 -0.141064 -0.110517  \n",
       "4 -0.014782 -0.177247  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(scaled_features, columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (3603, 16), X_test(901, 16), Y_train(3603,), Y_test(901,)\n"
     ]
    }
   ],
   "source": [
    "# Set the X and ys\n",
    "X = df_feat\n",
    "Y = df[df.columns[16]].astype('float')\n",
    "\n",
    "# Use the train_test_split() method to split the data into respective sets\n",
    "# test_size -> argument refers to the size of the test subset\n",
    "# random_state -> argument ensures guarantee that the output of Run \n",
    "# 1 will be equal to the output of Run 2, i.e. your split will be always the same\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
    "print(\"X_train {}, X_test{}, Y_train{}, Y_test{}\".format(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 901 points : 471, performance 47.72%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, Y_train)\n",
    "Y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(X_test.shape[0], (Y_test != Y_pred).sum(), 100 * (1 - (Y_test != Y_pred).sum() / X_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.69      0.56       435\n",
      "         1.0       0.49      0.27      0.35       466\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       901\n",
      "   macro avg       0.48      0.48      0.46       901\n",
      "weighted avg       0.48      0.48      0.45       901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import module for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create KNN instance\n",
    "# n_neighbors -> argument identifies the amount of neighbors used to ID classification\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# Fit (i.e. traing) the model\n",
    "knn.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 901 points : 332, performance 63.15%\n"
     ]
    }
   ],
   "source": [
    "# Use the .predict() method to make predictions from the X_test subset\n",
    "Y_pred = knn.predict(X_test)\n",
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(X_test.shape[0], (Y_test != Y_pred).sum(), 100 * (1 - (Y_test != Y_pred).sum() / X_test.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      0.93      0.96        14\n",
      "         3.0       0.96      1.00      0.98        23\n",
      "         4.0       0.89      0.92      0.91        52\n",
      "         5.0       0.87      0.86      0.87        64\n",
      "         6.0       0.77      0.61      0.68        28\n",
      "         7.0       0.59      0.59      0.59        22\n",
      "         8.0       0.63      0.55      0.59        22\n",
      "         9.0       0.51      0.64      0.57        28\n",
      "        10.0       0.50      0.32      0.39        22\n",
      "        11.0       0.30      0.32      0.31        19\n",
      "        12.0       0.50      0.56      0.53        27\n",
      "        13.0       0.47      0.61      0.53        23\n",
      "        14.0       0.68      0.50      0.58        26\n",
      "        15.0       0.64      0.67      0.65        27\n",
      "        16.0       0.68      0.76      0.72        25\n",
      "        17.0       0.58      0.64      0.61        22\n",
      "        18.0       0.63      0.71      0.67        24\n",
      "        19.0       0.70      0.64      0.67        22\n",
      "        20.0       0.74      0.70      0.72        20\n",
      "        21.0       0.71      0.60      0.65        20\n",
      "        22.0       0.69      0.61      0.65        18\n",
      "        23.0       0.75      0.56      0.64        27\n",
      "        24.0       0.38      0.64      0.47        14\n",
      "        25.0       0.60      0.53      0.56        17\n",
      "        26.0       0.43      0.64      0.51        14\n",
      "        27.0       0.62      0.62      0.62        16\n",
      "        28.0       0.71      0.62      0.67         8\n",
      "        29.0       0.85      0.65      0.73        17\n",
      "        30.0       0.33      0.36      0.35        11\n",
      "        31.0       0.36      0.50      0.42         8\n",
      "        32.0       0.50      0.60      0.55        10\n",
      "        33.0       0.70      0.70      0.70        10\n",
      "        34.0       0.80      0.80      0.80        20\n",
      "        35.0       0.67      0.55      0.60        11\n",
      "        36.0       0.55      0.60      0.57        10\n",
      "        37.0       0.62      0.56      0.59         9\n",
      "        38.0       0.33      0.14      0.20         7\n",
      "        39.0       0.20      0.25      0.22         4\n",
      "        40.0       0.55      0.67      0.60         9\n",
      "        41.0       0.60      0.60      0.60         5\n",
      "        42.0       0.67      0.33      0.44         6\n",
      "        43.0       1.00      0.33      0.50         6\n",
      "        44.0       0.67      0.33      0.44         6\n",
      "        45.0       0.14      0.33      0.20         3\n",
      "        46.0       0.43      0.75      0.55         4\n",
      "        47.0       0.71      0.91      0.80        11\n",
      "        48.0       0.20      1.00      0.33         1\n",
      "        49.0       0.50      0.60      0.55         5\n",
      "        50.0       0.50      0.33      0.40         3\n",
      "        51.0       0.50      0.20      0.29         5\n",
      "        52.0       0.00      0.00      0.00         0\n",
      "        53.0       0.00      0.00      0.00         4\n",
      "        54.0       0.20      0.25      0.22         4\n",
      "        55.0       0.00      0.00      0.00         2\n",
      "        56.0       0.33      0.25      0.29         4\n",
      "        58.0       1.00      0.67      0.80         3\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         0\n",
      "        61.0       1.00      0.67      0.80         3\n",
      "        62.0       0.75      1.00      0.86         3\n",
      "        63.0       1.00      0.75      0.86         4\n",
      "        65.0       1.00      0.33      0.50         3\n",
      "        66.0       0.80      1.00      0.89         4\n",
      "        67.0       0.33      0.25      0.29         4\n",
      "        68.0       0.00      0.00      0.00         0\n",
      "        69.0       0.00      0.00      0.00         3\n",
      "        70.0       0.00      0.00      0.00         1\n",
      "        71.0       0.00      0.00      0.00         1\n",
      "        72.0       0.00      0.00      0.00         0\n",
      "        74.0       1.00      0.50      0.67         2\n",
      "        78.0       0.00      0.00      0.00         0\n",
      "        79.0       0.00      0.00      0.00         0\n",
      "        81.0       0.00      0.00      0.00         0\n",
      "        83.0       1.00      1.00      1.00         1\n",
      "        84.0       0.00      0.00      0.00         2\n",
      "        85.0       1.00      1.00      1.00         1\n",
      "        91.0       1.00      1.00      1.00         3\n",
      "        92.0       0.50      1.00      0.67         1\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       0.00      0.00      0.00         1\n",
      "        96.0       0.50      1.00      0.67         1\n",
      "        97.0       0.00      0.00      0.00         2\n",
      "        98.0       1.00      1.00      1.00         1\n",
      "        99.0       0.00      0.00      0.00         1\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         1\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       104.0       0.00      0.00      0.00         0\n",
      "       105.0       0.50      1.00      0.67         1\n",
      "       119.0       0.50      1.00      0.67         1\n",
      "       121.0       1.00      0.50      0.67         2\n",
      "       127.0       1.00      1.00      1.00         1\n",
      "       133.0       1.00      1.00      1.00         1\n",
      "       137.0       0.00      0.00      0.00         0\n",
      "       139.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       901\n",
      "   macro avg       0.49      0.49      0.47       901\n",
      "weighted avg       0.65      0.63      0.63       901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.feature_selection import RFE\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "# rfe = RFE(logreg, 20)\n",
    "# rfe = rfe.fit(X_train, Y_train)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.16759156492785793\n"
     ]
    }
   ],
   "source": [
    "# Use the .predict() method to make predictions from the X_test subset\n",
    "Y_pred = logreg.predict(X_test)\n",
    "# Print results\n",
    "print(\"Accuracy is \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.00      0.00      0.00        23\n",
      "         4.0       0.31      0.92      0.47        52\n",
      "         5.0       0.32      0.11      0.16        64\n",
      "         6.0       0.50      0.11      0.18        28\n",
      "         7.0       0.12      0.32      0.18        22\n",
      "         8.0       0.18      0.09      0.12        22\n",
      "         9.0       0.19      0.29      0.23        28\n",
      "        10.0       0.25      0.09      0.13        22\n",
      "        11.0       0.00      0.00      0.00        19\n",
      "        12.0       0.05      0.04      0.04        27\n",
      "        13.0       0.12      0.09      0.10        23\n",
      "        14.0       0.00      0.00      0.00        26\n",
      "        15.0       0.14      0.52      0.22        27\n",
      "        16.0       0.07      0.08      0.07        25\n",
      "        17.0       0.33      0.23      0.27        22\n",
      "        18.0       0.07      0.08      0.08        24\n",
      "        19.0       0.67      0.18      0.29        22\n",
      "        20.0       0.00      0.00      0.00        20\n",
      "        21.0       0.11      0.10      0.10        20\n",
      "        22.0       0.11      0.06      0.07        18\n",
      "        23.0       0.18      0.07      0.11        27\n",
      "        24.0       0.04      0.21      0.07        14\n",
      "        25.0       0.00      0.00      0.00        17\n",
      "        26.0       0.00      0.00      0.00        14\n",
      "        27.0       0.00      0.00      0.00        16\n",
      "        28.0       0.14      0.12      0.13         8\n",
      "        29.0       0.17      0.41      0.24        17\n",
      "        30.0       0.00      0.00      0.00        11\n",
      "        31.0       0.00      0.00      0.00         8\n",
      "        32.0       0.00      0.00      0.00        10\n",
      "        33.0       0.17      0.10      0.12        10\n",
      "        34.0       0.10      0.40      0.16        20\n",
      "        35.0       0.00      0.00      0.00        11\n",
      "        36.0       0.00      0.00      0.00        10\n",
      "        37.0       0.17      0.33      0.22         9\n",
      "        38.0       0.00      0.00      0.00         7\n",
      "        39.0       0.00      0.00      0.00         4\n",
      "        40.0       0.44      0.44      0.44         9\n",
      "        41.0       0.00      0.00      0.00         5\n",
      "        42.0       0.00      0.00      0.00         6\n",
      "        43.0       1.00      0.33      0.50         6\n",
      "        44.0       0.14      0.17      0.15         6\n",
      "        45.0       0.00      0.00      0.00         3\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.00      0.00      0.00        11\n",
      "        48.0       0.00      0.00      0.00         1\n",
      "        49.0       0.00      0.00      0.00         5\n",
      "        50.0       0.00      0.00      0.00         3\n",
      "        51.0       0.00      0.00      0.00         5\n",
      "        52.0       0.00      0.00      0.00         0\n",
      "        53.0       0.00      0.00      0.00         4\n",
      "        54.0       0.00      0.00      0.00         4\n",
      "        55.0       0.00      0.00      0.00         2\n",
      "        56.0       0.00      0.00      0.00         4\n",
      "        58.0       0.00      0.00      0.00         3\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         0\n",
      "        61.0       0.00      0.00      0.00         3\n",
      "        62.0       0.50      0.67      0.57         3\n",
      "        63.0       0.00      0.00      0.00         4\n",
      "        65.0       0.00      0.00      0.00         3\n",
      "        66.0       0.18      1.00      0.31         4\n",
      "        67.0       0.00      0.00      0.00         4\n",
      "        69.0       0.00      0.00      0.00         3\n",
      "        70.0       0.00      0.00      0.00         1\n",
      "        71.0       0.00      0.00      0.00         1\n",
      "        74.0       0.00      0.00      0.00         2\n",
      "        83.0       0.00      0.00      0.00         1\n",
      "        84.0       0.00      0.00      0.00         2\n",
      "        85.0       0.00      0.00      0.00         1\n",
      "        91.0       0.00      0.00      0.00         3\n",
      "        92.0       0.00      0.00      0.00         1\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       0.00      0.00      0.00         1\n",
      "        96.0       0.50      1.00      0.67         1\n",
      "        97.0       0.00      0.00      0.00         2\n",
      "        98.0       1.00      1.00      1.00         1\n",
      "        99.0       0.00      0.00      0.00         1\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         1\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       105.0       0.33      1.00      0.50         1\n",
      "       119.0       0.00      0.00      0.00         1\n",
      "       121.0       0.00      0.00      0.00         2\n",
      "       127.0       0.00      0.00      0.00         1\n",
      "       133.0       0.00      0.00      0.00         1\n",
      "       137.0       0.00      0.00      0.00         0\n",
      "       139.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.17      0.17      0.17       901\n",
      "   macro avg       0.10      0.12      0.09       901\n",
      "weighted avg       0.15      0.17      0.13       901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "clf_gini.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.21309655937846836\n"
     ]
    }
   ],
   "source": [
    "# Use the .predict() method to make predictions from the X_test subset\n",
    "Y_pred = clf_gini.predict(X_test)\n",
    "# Print results\n",
    "print(\"Accuracy is \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "         2.0       0.72      0.93      0.81        14\n",
      "         3.0       0.95      0.78      0.86        23\n",
      "         4.0       0.78      0.83      0.80        52\n",
      "         5.0       0.70      0.83      0.76        64\n",
      "         6.0       0.00      0.00      0.00        28\n",
      "         7.0       0.24      0.64      0.35        22\n",
      "         8.0       0.00      0.00      0.00        22\n",
      "         9.0       0.23      0.57      0.32        28\n",
      "        10.0       0.00      0.00      0.00        22\n",
      "        11.0       0.00      0.00      0.00        19\n",
      "        12.0       0.00      0.00      0.00        27\n",
      "        13.0       0.00      0.00      0.00        23\n",
      "        14.0       0.00      0.00      0.00        26\n",
      "        15.0       0.18      0.78      0.29        27\n",
      "        16.0       0.00      0.00      0.00        25\n",
      "        17.0       0.00      0.00      0.00        22\n",
      "        18.0       0.00      0.00      0.00        24\n",
      "        19.0       0.00      0.00      0.00        22\n",
      "        20.0       0.00      0.00      0.00        20\n",
      "        21.0       0.00      0.00      0.00        20\n",
      "        22.0       0.00      0.00      0.00        18\n",
      "        23.0       0.00      0.00      0.00        27\n",
      "        24.0       0.03      1.00      0.06        14\n",
      "        25.0       0.00      0.00      0.00        17\n",
      "        26.0       0.00      0.00      0.00        14\n",
      "        27.0       0.00      0.00      0.00        16\n",
      "        28.0       0.00      0.00      0.00         8\n",
      "        29.0       0.00      0.00      0.00        17\n",
      "        30.0       0.00      0.00      0.00        11\n",
      "        31.0       0.00      0.00      0.00         8\n",
      "        32.0       0.00      0.00      0.00        10\n",
      "        33.0       0.00      0.00      0.00        10\n",
      "        34.0       0.00      0.00      0.00        20\n",
      "        35.0       0.00      0.00      0.00        11\n",
      "        36.0       0.00      0.00      0.00        10\n",
      "        37.0       0.00      0.00      0.00         9\n",
      "        38.0       0.00      0.00      0.00         7\n",
      "        39.0       0.00      0.00      0.00         4\n",
      "        40.0       0.00      0.00      0.00         9\n",
      "        41.0       0.00      0.00      0.00         5\n",
      "        42.0       0.00      0.00      0.00         6\n",
      "        43.0       0.00      0.00      0.00         6\n",
      "        44.0       0.00      0.00      0.00         6\n",
      "        45.0       0.00      0.00      0.00         3\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.00      0.00      0.00        11\n",
      "        48.0       0.00      0.00      0.00         1\n",
      "        49.0       0.00      0.00      0.00         5\n",
      "        50.0       0.00      0.00      0.00         3\n",
      "        51.0       0.00      0.00      0.00         5\n",
      "        53.0       0.00      0.00      0.00         4\n",
      "        54.0       0.00      0.00      0.00         4\n",
      "        55.0       0.00      0.00      0.00         2\n",
      "        56.0       0.00      0.00      0.00         4\n",
      "        58.0       0.00      0.00      0.00         3\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        61.0       0.00      0.00      0.00         3\n",
      "        62.0       0.00      0.00      0.00         3\n",
      "        63.0       0.00      0.00      0.00         4\n",
      "        65.0       0.00      0.00      0.00         3\n",
      "        66.0       0.00      0.00      0.00         4\n",
      "        67.0       0.00      0.00      0.00         4\n",
      "        69.0       0.00      0.00      0.00         3\n",
      "        70.0       0.00      0.00      0.00         1\n",
      "        71.0       0.00      0.00      0.00         1\n",
      "        74.0       0.00      0.00      0.00         2\n",
      "        83.0       0.00      0.00      0.00         1\n",
      "        84.0       0.00      0.00      0.00         2\n",
      "        85.0       0.00      0.00      0.00         1\n",
      "        91.0       0.00      0.00      0.00         3\n",
      "        92.0       0.00      0.00      0.00         1\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       0.00      0.00      0.00         1\n",
      "        96.0       0.00      0.00      0.00         1\n",
      "        97.0       0.00      0.00      0.00         2\n",
      "        98.0       0.00      0.00      0.00         1\n",
      "        99.0       0.00      0.00      0.00         1\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         1\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       105.0       0.00      0.00      0.00         1\n",
      "       119.0       0.00      0.00      0.00         1\n",
      "       121.0       0.00      0.00      0.00         2\n",
      "       127.0       0.00      0.00      0.00         1\n",
      "       133.0       0.00      0.00      0.00         1\n",
      "       139.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.21      0.21      0.21       901\n",
      "   macro avg       0.04      0.07      0.05       901\n",
      "weighted avg       0.15      0.21      0.16       901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(gamma=0.001, C=100.)\n",
    "clf_svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.27524972253052166\n"
     ]
    }
   ],
   "source": [
    "# Use the .predict() method to make predictions from the X_test subset\n",
    "Y_pred = clf_svm.predict(X_test)\n",
    "# Print results\n",
    "print(\"Accuracy is \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "         2.0       0.00      0.00      0.00        14\n",
      "         3.0       0.35      0.61      0.44        23\n",
      "         4.0       0.40      0.67      0.50        52\n",
      "         5.0       0.44      0.31      0.37        64\n",
      "         6.0       0.60      0.21      0.32        28\n",
      "         7.0       0.23      0.64      0.34        22\n",
      "         8.0       0.00      0.00      0.00        22\n",
      "         9.0       0.23      0.36      0.28        28\n",
      "        10.0       0.20      0.05      0.07        22\n",
      "        11.0       0.31      0.21      0.25        19\n",
      "        12.0       0.08      0.04      0.05        27\n",
      "        13.0       0.14      0.22      0.17        23\n",
      "        14.0       1.00      0.04      0.07        26\n",
      "        15.0       0.21      0.59      0.31        27\n",
      "        16.0       0.16      0.16      0.16        25\n",
      "        17.0       0.64      0.32      0.42        22\n",
      "        18.0       0.25      0.21      0.23        24\n",
      "        19.0       0.50      0.32      0.39        22\n",
      "        20.0       0.33      0.65      0.44        20\n",
      "        21.0       1.00      0.05      0.10        20\n",
      "        22.0       0.25      0.06      0.09        18\n",
      "        23.0       0.29      0.41      0.34        27\n",
      "        24.0       0.13      0.43      0.20        14\n",
      "        25.0       1.00      0.06      0.11        17\n",
      "        26.0       0.00      0.00      0.00        14\n",
      "        27.0       0.13      0.19      0.15        16\n",
      "        28.0       1.00      0.12      0.22         8\n",
      "        29.0       0.20      0.41      0.27        17\n",
      "        30.0       0.00      0.00      0.00        11\n",
      "        31.0       0.00      0.00      0.00         8\n",
      "        32.0       0.44      0.40      0.42        10\n",
      "        33.0       0.33      0.40      0.36        10\n",
      "        34.0       0.33      0.70      0.44        20\n",
      "        35.0       0.00      0.00      0.00        11\n",
      "        36.0       0.00      0.00      0.00        10\n",
      "        37.0       0.44      0.44      0.44         9\n",
      "        38.0       0.50      0.14      0.22         7\n",
      "        39.0       0.00      0.00      0.00         4\n",
      "        40.0       1.00      0.22      0.36         9\n",
      "        41.0       0.11      0.40      0.17         5\n",
      "        42.0       0.00      0.00      0.00         6\n",
      "        43.0       0.00      0.00      0.00         6\n",
      "        44.0       0.20      0.17      0.18         6\n",
      "        45.0       0.00      0.00      0.00         3\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.25      0.55      0.34        11\n",
      "        48.0       1.00      1.00      1.00         1\n",
      "        49.0       0.00      0.00      0.00         5\n",
      "        50.0       0.00      0.00      0.00         3\n",
      "        51.0       1.00      0.20      0.33         5\n",
      "        52.0       0.00      0.00      0.00         0\n",
      "        53.0       0.00      0.00      0.00         4\n",
      "        54.0       0.00      0.00      0.00         4\n",
      "        55.0       0.00      0.00      0.00         2\n",
      "        56.0       0.00      0.00      0.00         4\n",
      "        58.0       0.00      0.00      0.00         3\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         0\n",
      "        61.0       0.00      0.00      0.00         3\n",
      "        62.0       0.50      1.00      0.67         3\n",
      "        63.0       0.00      0.00      0.00         4\n",
      "        65.0       0.00      0.00      0.00         3\n",
      "        66.0       0.20      0.75      0.32         4\n",
      "        67.0       0.60      0.75      0.67         4\n",
      "        69.0       0.00      0.00      0.00         3\n",
      "        70.0       0.00      0.00      0.00         1\n",
      "        71.0       0.00      0.00      0.00         1\n",
      "        74.0       0.00      0.00      0.00         2\n",
      "        83.0       0.50      1.00      0.67         1\n",
      "        84.0       0.00      0.00      0.00         2\n",
      "        85.0       0.00      0.00      0.00         1\n",
      "        86.0       0.00      0.00      0.00         0\n",
      "        91.0       0.00      0.00      0.00         3\n",
      "        92.0       0.20      1.00      0.33         1\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       0.00      0.00      0.00         1\n",
      "        96.0       0.50      1.00      0.67         1\n",
      "        97.0       0.00      0.00      0.00         2\n",
      "        98.0       1.00      1.00      1.00         1\n",
      "        99.0       0.00      0.00      0.00         1\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         1\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       105.0       0.20      1.00      0.33         1\n",
      "       117.0       0.00      0.00      0.00         0\n",
      "       119.0       0.00      0.00      0.00         1\n",
      "       121.0       0.00      0.00      0.00         2\n",
      "       126.0       0.00      0.00      0.00         0\n",
      "       127.0       0.00      0.00      0.00         1\n",
      "       133.0       0.00      0.00      0.00         1\n",
      "       137.0       0.00      0.00      0.00         0\n",
      "       139.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       901\n",
      "   macro avg       0.21      0.21      0.16       901\n",
      "weighted avg       0.32      0.28      0.23       901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf  = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "clf_rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.8013318534961155\n"
     ]
    }
   ],
   "source": [
    "# Use the .predict() method to make predictions from the X_test subset\n",
    "Y_pred = clf_rf.predict(X_test)\n",
    "# Print results\n",
    "print(\"Accuracy is \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00        14\n",
      "         3.0       1.00      1.00      1.00        23\n",
      "         4.0       1.00      0.98      0.99        52\n",
      "         5.0       0.94      0.95      0.95        64\n",
      "         6.0       0.78      0.75      0.76        28\n",
      "         7.0       0.63      0.77      0.69        22\n",
      "         8.0       0.84      0.73      0.78        22\n",
      "         9.0       0.69      0.79      0.73        28\n",
      "        10.0       0.72      0.59      0.65        22\n",
      "        11.0       0.94      0.84      0.89        19\n",
      "        12.0       0.79      0.85      0.82        27\n",
      "        13.0       0.71      0.74      0.72        23\n",
      "        14.0       0.83      0.73      0.78        26\n",
      "        15.0       0.86      0.67      0.75        27\n",
      "        16.0       0.74      0.92      0.82        25\n",
      "        17.0       0.86      0.82      0.84        22\n",
      "        18.0       0.79      0.92      0.85        24\n",
      "        19.0       0.83      0.91      0.87        22\n",
      "        20.0       1.00      0.85      0.92        20\n",
      "        21.0       0.76      0.80      0.78        20\n",
      "        22.0       0.81      0.72      0.76        18\n",
      "        23.0       0.87      0.74      0.80        27\n",
      "        24.0       0.52      0.86      0.65        14\n",
      "        25.0       0.64      0.41      0.50        17\n",
      "        26.0       0.73      0.79      0.76        14\n",
      "        27.0       0.86      0.75      0.80        16\n",
      "        28.0       0.67      0.75      0.71         8\n",
      "        29.0       0.88      0.82      0.85        17\n",
      "        30.0       0.57      0.73      0.64        11\n",
      "        31.0       0.57      0.50      0.53         8\n",
      "        32.0       0.57      0.80      0.67        10\n",
      "        33.0       0.88      0.70      0.78        10\n",
      "        34.0       0.90      0.90      0.90        20\n",
      "        35.0       0.83      0.91      0.87        11\n",
      "        36.0       0.70      0.70      0.70        10\n",
      "        37.0       0.78      0.78      0.78         9\n",
      "        38.0       0.67      0.86      0.75         7\n",
      "        39.0       0.75      0.75      0.75         4\n",
      "        40.0       1.00      0.89      0.94         9\n",
      "        41.0       0.67      0.80      0.73         5\n",
      "        42.0       0.71      0.83      0.77         6\n",
      "        43.0       1.00      0.33      0.50         6\n",
      "        44.0       1.00      0.50      0.67         6\n",
      "        45.0       0.17      0.33      0.22         3\n",
      "        46.0       0.75      0.75      0.75         4\n",
      "        47.0       0.92      1.00      0.96        11\n",
      "        48.0       1.00      1.00      1.00         1\n",
      "        49.0       1.00      0.60      0.75         5\n",
      "        50.0       1.00      1.00      1.00         3\n",
      "        51.0       0.57      0.80      0.67         5\n",
      "        53.0       1.00      0.50      0.67         4\n",
      "        54.0       0.20      0.25      0.22         4\n",
      "        55.0       0.00      0.00      0.00         2\n",
      "        56.0       0.67      0.50      0.57         4\n",
      "        58.0       1.00      0.33      0.50         3\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         0\n",
      "        61.0       1.00      0.67      0.80         3\n",
      "        62.0       1.00      1.00      1.00         3\n",
      "        63.0       1.00      0.75      0.86         4\n",
      "        65.0       1.00      0.33      0.50         3\n",
      "        66.0       0.67      1.00      0.80         4\n",
      "        67.0       0.75      0.75      0.75         4\n",
      "        69.0       1.00      0.67      0.80         3\n",
      "        70.0       1.00      1.00      1.00         1\n",
      "        71.0       1.00      1.00      1.00         1\n",
      "        74.0       1.00      1.00      1.00         2\n",
      "        83.0       1.00      1.00      1.00         1\n",
      "        84.0       1.00      1.00      1.00         2\n",
      "        85.0       1.00      1.00      1.00         1\n",
      "        91.0       1.00      1.00      1.00         3\n",
      "        92.0       0.50      1.00      0.67         1\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       1.00      1.00      1.00         1\n",
      "        96.0       1.00      1.00      1.00         1\n",
      "        97.0       0.50      1.00      0.67         2\n",
      "        98.0       1.00      1.00      1.00         1\n",
      "        99.0       1.00      1.00      1.00         1\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         1\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       104.0       0.00      0.00      0.00         0\n",
      "       105.0       0.50      1.00      0.67         1\n",
      "       119.0       1.00      1.00      1.00         1\n",
      "       121.0       1.00      1.00      1.00         2\n",
      "       127.0       1.00      1.00      1.00         1\n",
      "       133.0       1.00      1.00      1.00         1\n",
      "       139.0       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       901\n",
      "   macro avg       0.76      0.74      0.73       901\n",
      "weighted avg       0.82      0.80      0.80       901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.8013318534961155\n"
     ]
    }
   ],
   "source": [
    "# Use the .predict() method to make predictions from the X_test subset\n",
    "Y_pred = clf_rf.predict(X_test)\n",
    "# Print results\n",
    "print(\"Accuracy is \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "         2.0       1.00      1.00      1.00        14\n",
      "         3.0       1.00      1.00      1.00        23\n",
      "         4.0       1.00      0.98      0.99        52\n",
      "         5.0       0.94      0.95      0.95        64\n",
      "         6.0       0.78      0.75      0.76        28\n",
      "         7.0       0.63      0.77      0.69        22\n",
      "         8.0       0.84      0.73      0.78        22\n",
      "         9.0       0.69      0.79      0.73        28\n",
      "        10.0       0.72      0.59      0.65        22\n",
      "        11.0       0.94      0.84      0.89        19\n",
      "        12.0       0.79      0.85      0.82        27\n",
      "        13.0       0.71      0.74      0.72        23\n",
      "        14.0       0.83      0.73      0.78        26\n",
      "        15.0       0.86      0.67      0.75        27\n",
      "        16.0       0.74      0.92      0.82        25\n",
      "        17.0       0.86      0.82      0.84        22\n",
      "        18.0       0.79      0.92      0.85        24\n",
      "        19.0       0.83      0.91      0.87        22\n",
      "        20.0       1.00      0.85      0.92        20\n",
      "        21.0       0.76      0.80      0.78        20\n",
      "        22.0       0.81      0.72      0.76        18\n",
      "        23.0       0.87      0.74      0.80        27\n",
      "        24.0       0.52      0.86      0.65        14\n",
      "        25.0       0.64      0.41      0.50        17\n",
      "        26.0       0.73      0.79      0.76        14\n",
      "        27.0       0.86      0.75      0.80        16\n",
      "        28.0       0.67      0.75      0.71         8\n",
      "        29.0       0.88      0.82      0.85        17\n",
      "        30.0       0.57      0.73      0.64        11\n",
      "        31.0       0.57      0.50      0.53         8\n",
      "        32.0       0.57      0.80      0.67        10\n",
      "        33.0       0.88      0.70      0.78        10\n",
      "        34.0       0.90      0.90      0.90        20\n",
      "        35.0       0.83      0.91      0.87        11\n",
      "        36.0       0.70      0.70      0.70        10\n",
      "        37.0       0.78      0.78      0.78         9\n",
      "        38.0       0.67      0.86      0.75         7\n",
      "        39.0       0.75      0.75      0.75         4\n",
      "        40.0       1.00      0.89      0.94         9\n",
      "        41.0       0.67      0.80      0.73         5\n",
      "        42.0       0.71      0.83      0.77         6\n",
      "        43.0       1.00      0.33      0.50         6\n",
      "        44.0       1.00      0.50      0.67         6\n",
      "        45.0       0.17      0.33      0.22         3\n",
      "        46.0       0.75      0.75      0.75         4\n",
      "        47.0       0.92      1.00      0.96        11\n",
      "        48.0       1.00      1.00      1.00         1\n",
      "        49.0       1.00      0.60      0.75         5\n",
      "        50.0       1.00      1.00      1.00         3\n",
      "        51.0       0.57      0.80      0.67         5\n",
      "        53.0       1.00      0.50      0.67         4\n",
      "        54.0       0.20      0.25      0.22         4\n",
      "        55.0       0.00      0.00      0.00         2\n",
      "        56.0       0.67      0.50      0.57         4\n",
      "        58.0       1.00      0.33      0.50         3\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         0\n",
      "        61.0       1.00      0.67      0.80         3\n",
      "        62.0       1.00      1.00      1.00         3\n",
      "        63.0       1.00      0.75      0.86         4\n",
      "        65.0       1.00      0.33      0.50         3\n",
      "        66.0       0.67      1.00      0.80         4\n",
      "        67.0       0.75      0.75      0.75         4\n",
      "        69.0       1.00      0.67      0.80         3\n",
      "        70.0       1.00      1.00      1.00         1\n",
      "        71.0       1.00      1.00      1.00         1\n",
      "        74.0       1.00      1.00      1.00         2\n",
      "        83.0       1.00      1.00      1.00         1\n",
      "        84.0       1.00      1.00      1.00         2\n",
      "        85.0       1.00      1.00      1.00         1\n",
      "        91.0       1.00      1.00      1.00         3\n",
      "        92.0       0.50      1.00      0.67         1\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       1.00      1.00      1.00         1\n",
      "        96.0       1.00      1.00      1.00         1\n",
      "        97.0       0.50      1.00      0.67         2\n",
      "        98.0       1.00      1.00      1.00         1\n",
      "        99.0       1.00      1.00      1.00         1\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         1\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       104.0       0.00      0.00      0.00         0\n",
      "       105.0       0.50      1.00      0.67         1\n",
      "       119.0       1.00      1.00      1.00         1\n",
      "       121.0       1.00      1.00      1.00         2\n",
      "       127.0       1.00      1.00      1.00         1\n",
      "       133.0       1.00      1.00      1.00         1\n",
      "       139.0       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       901\n",
      "   macro avg       0.76      0.74      0.73       901\n",
      "weighted avg       0.82      0.80      0.80       901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sand1k/repos/defect_predictor/jupyter_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report and confusion matrix\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
